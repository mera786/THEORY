BASIC  :
-----------

Q1. What is Apache Kafka?
-> Apache Kafka is a tool.
-> It acts as mediator between services to exchange messages (Message Broker) where Publisher will publish the message and subscriber will consume the message.
-> Kafka is very useful for real time data exchange.

Q2. Why do we use Kafka?
üëâ We use Kafka to move data quickly from one system to another (real-time data pipelines) and to process data immediately when it comes (real-time streaming).
e.g., ‚Äúlike YouTube live chat messages"

Q3.Advantages and Disadvantage of kafka ?
Advantages of Kafka :
- Scalability ‚Äì Can easily handle very large amounts of data by adding more servers.
- Fault Tolerance ‚Äì Data is replicated (copied) across servers, so even if one fails, data is safe.
- High Throughput ‚Äì Can process millions of messages per second with very low delay.
- Durability ‚Äì Stores data reliably on disk, so messages are not lost.
- Real-Time Processing ‚Äì Best for real-time streaming (like live chats, stock prices, logs).
Disadvantages of Kafka :
- Complex Setup ‚Äì Harder to install, configure, and maintain compared to simple queues.
- High Learning Curve ‚Äì Developers need to spend time learning concepts (brokers, topics, partitions).
- Not Ideal for Small Data ‚Äì Overkill if you only need to process small or simple workloads.
- Resource Usage ‚Äì Needs good CPU, memory, and storage for large-scale usage.
- Limited Message Prioritization ‚Äì All messages in a topic are treated equally; no built-in priority handling.


Q4. Explain Kafka Architecture / Key Component of Kafka ?
            a. Zookeeper/Kraft
            b. Kafka Server / Kafka Brokers 
            c. Kafka Topic
            d. Partitions
            e. Publisher/producer
            f. Subscriber/consumer

Q5. What is Zookeeper in Kafka?
Zookeeper (old way)
üëâ It is an external tool that manages the Kafka cluster. It keeps track of which brokers are alive, who is the leader of a partition, and stores cluster metadata.

Q6. What is KRaft in Kafka?
KRaft (new way)
üëâ It is Kafka‚Äôs own built-in system (no need for Zookeeper). It directly manages brokers, topics, partitions, and leaders inside Kafka itself, making Kafka simpler and faster.


Q7. What is a Kafka Server / Kafka Brokers  ?
Kafka Server / Kafka Brokers
üëâ A broker is just a Kafka server (machine running Kafka).
üëâ It stores the messages (data) and sends them to consumers when asked.
üëâ One broker alone can work, but usually we use many brokers together (this group is called a Kafka cluster) to share the load and keep data safe.


Q8. What is Kafka Topic ?
üëâ A category/channel where messages are stored.
Example: Topic orders will have all order-related messages.
Diagram :
+-----------------------+
|      Kafka Broker     |
|                       |
|   +-------------+     |
|   |   TopicA    |     |
|   +-------------+     |
|                       |
|   +-------------+     |
|   |   TopicB    |     |
|   +-------------+     |
+-----------------------+


Q9. What is Partitions ?
A partitions is a sub-section of a Kafka topic,each partition maintains a sequential order of messages, allowing prallel read and write for higher performance.
Diagram :
+-----------------------+
|      Kafka Broker     |
|                       |
|   +-------------+     |
|   |   TopicA    |     |
|   |-------------|     |
|   | Partition 0 |     |
|   | Partition 1 |     |
|   +-------------+     |
|                       |
|   +-------------+     |
|   |   TopicB    |     |
|   |-------------|     |
|   | Partition 0 |     |
|   | Partition 1 |     |
|   +-------------+     |
+-----------------------+

Q10. What is Publisher/producer ?
üëâ The application that sends data (messages) to Kafka topics.
Example: E-commerce app sends new order details to Kafka.

Q11. What is Subscriber/consumer ?
üëâ The application that reads data from Kafka topics.
Example: Billing system consumes order messages to generate invoices.
Diagram :
                        +-----------------------+     
                        |      Kafka Broker     |
                        |                       |
                        |   +-------------+     |
                        |   |   TopicA    |     |
                        |   |-------------|     |
             Producer ‚Üí |   | Partition 0 |     |  ‚Üê  Consumer
                        |   | Partition 1 |     |
                        |   +-------------+     |
                        |                       |
                        |   +-------------+     |
                        |   |   TopicB    |     |
                        |   |-------------|     |
                        |   | Partition 0 |     |
                        |   | Partition 1 |     |
                        |   +-------------+     |
                        +-----------------------+

Q12. What is a Consumer Group?
üëâ A group of consumers that share work of reading from a topic. Each partition is consumed by only one consumer in the group.
Daigram :
                 +-----------------------+
                 |      Kafka Broker     |
                 |                       |
                 |   +-------------+     |
                 |   |   TopicA    |     |
                 |   |-------------|     |
                 |   | Partition 0 |-----|----> Consumer 1
                 |   | Partition 1 |-----|----> Consumer 2
                 |   | Partition 2 |-----|----> Consumer 3
                 |   | Partition 3 |-----|----> Consumer 4
                 |   +-------------+     |
                 +-----------------------+
                        Consumer Group (Group ID = "Order-Service")


Q13. What is a Kafka Cluster?
-> A Kafka cluster is a group of Kafka brokers working together to manage message storage, distribution, and replication for high-throughput, fault-tolerant messaging.
Diagram :

          +===================================================================+
          |                         Kafka Cluster                             |
          |                                                                   |
          |   +------------------------+     +-----------------------------+  |
          |   |       Broker 1         |     |          Broker 2           |  |
          |   |------------------------|     |-----------------------------|  |
          |   |  TopicA                |     |  TopicA                     |  |
          |   |  +---------------+     |     |  +---------------+          |  |
Producer ‚Üí|   |  | Partition 0   |     |     |  | Partition 0   |          |  |‚Üê Consumer
          |   |  +---------------+     |     |  +---------------+          |  |
          |   |  | Partition 1   |     |     |  | Partition 1   |          |  |
          |   |  +---------------+     |     |  +---------------+          |  |
          |   |                        |     |                             |  |
          |   |  TopicB                |     |  TopicB                     |  |
          |   |  +---------------+     |     |  +---------------+          |  |
          |   |  | Partition 0   |     |     |  | Partition 0   |          |  |
          |   |  +---------------+     |     |  +---------------+          |  |
          |   +------------------------+     +-----------------------------+  |
          |                                                                   |
          +===================================================================+

eg-1 :
‚úÖ Kafka Cluster with 1 Broker, 1 Topic (3 Partitions), Replication Factor 1 (so no replicas ‚Äî each partition exists only once).
          +====================================================+
          |                  Kafka Cluster                     |
          |                                                    |
          |   +--------------------------------------------+   |
          |   |                Broker 1                    |   |
          |   |--------------------------------------------|   |
          |   |  TopicA                                    |   |
          |   |  +------------------+                      |   |
          |   |  | Partition 0      |  (Leader)            |   |
          |   |  +------------------+                      |   |
          |   |  | Partition 1      |  (Leader)            |   |
          |   |  +------------------+                      |   |
          |   |  | Partition 2      |  (Leader)            |   |
          |   |  +------------------+                      |   |
          |   +--------------------------------------------+   |
          |                                                    |
          +====================================================+

eg-2 :
‚úÖ Kafka Cluster with 2 Broker, 1 Topic (2 Partitions), Replication Factor 2.

            +===================================================================+
            |                           Kafka Cluster                           |
            |                                                                   |
            |   +------------------------+     +------------------------+       |
            |   |        Broker‚ÄØ1        |     |        Broker‚ÄØ2        |       |
            |   |------------------------|     |------------------------|       |
            |   |  TopicA                |     |  TopicA                |       |
            |   |  +------------------+  |     |  +------------------+  |       |
            |   |  | Partition‚ÄØ0      |  |     |  | Partition‚ÄØ0      |  |       |
            |   |  |  (Leader)        |  |     |  |  (Replica)       |  |       |
            |   |  +------------------+  |     |  +------------------+  |       |
            |   |  | Partition‚ÄØ1      |  |     |  | Partition‚ÄØ1      |  |       |
            |   |  |  (Replica)       |  |     |  |  (Leader)        |  |       |
            |   |  +------------------+  |     |  +------------------+  |       |
            |   +------------------------+     +------------------------+       |
            |                                                                   |
            +===================================================================+






(2) Installation & Setup :
---------------------------

Q1. How do you install Kafka locally?
       - Download Kafka from the official Apache site.
       - Extract the tar file.
       - Start Zookeeper: bin/zookeeper-server-start.sh config/zookeeper.properties
       - Start Kafka Broker: bin/kafka-server-start.sh config/server.properties

Q2. What are Kafka prerequisites?
Java 8+, sufficient memory {RAM (Random Access Memory) on the machine} , Zookeeper (unless using KRaft mode).

Q3. What is the default Kafka port?
9092.

Q4. How do you secure Kafka?
here secure Kafka means :
            - Only authorized users or applications can produce or consume messages.
            - Messages aren‚Äôt intercepted or read by outsiders during transmission.
            - Sensitive information (like passwords, tokens, or configs) is not exposed.
There are some security mechanisms :
| Security Method                     | What it does                                                                                                                        |
| ----------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |
| **SSL/TLS encryption**              | Encrypts data in transit between clients (producers/consumers) and brokers so that attackers cannot read messages from the network. |
| **SASL authentication**             | Ensures only authenticated users or applications can connect to Kafka (like username/password or Kerberos).                         |
| **ACLs (Access Control Lists)**     | Control which users or apps can read/write to specific topics or perform admin actions.                                             |
| **Encrypt sensitive configuration** | Keeps credentials (like SASL passwords) safe in config files or environment variables.                                              |

Q5. How do you start and stop Kafka?
Use kafka-server-start.sh and kafka-server-stop.sh for brokers; zookeeper-server-start.sh / stop for Zookeeper (if applicable). on cmd 

Q6. How do you set up Kafka on Docker?
For local or small setups, you can use Docker Compose with official Kafka images, configuring brokers, ports, and environment variables. For production-grade deployments, you can use Kubernetes, deploying Kafka and Zookeeper as StatefulSets with PersistentVolumes, configuring services for access, and optionally using Helm charts for easier management.





(3) Kafka Producers & Consumers :
----------------------------------

Q1. How do you create a Kafka Producer in Spring Boot?
Use KafkaTemplate<String, String> and @Bean configuration with ProducerFactory.
By Following Steps :
1Ô∏è‚É£ Add dependencies in pom.xml:
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
</dependency>
2Ô∏è‚É£ Configure Producer in a @Configuration class:
@Configuration
public class KafkaProducerConfig {
    @Bean
    public ProducerFactory<String, String> producerFactory() {
        Map<String, Object> configProps = new HashMap<>();
        configProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092"); // Kafka broker
        configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class); 
        configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        return new DefaultKafkaProducerFactory<>(configProps);
    }
    @Bean
    public KafkaTemplate<String, String> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }
}
Note:- Explanation of stored map data :
    - configProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092"); // 
                     üëç Specifies the Kafka broker‚Äôs address so the producer knows where to send messages.
    - configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
                     üëç Converts the message key (used for partitioning) from Java type ‚Üí byte stream before sending to Kafka.
    - configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
                     üëç Converts the message value (actual message body) from Java type ‚Üí byte stream before sending to Kafka.
3Ô∏è‚É£ Send messages using KafkaTemplate:
@Service
public class ProducerService {
    private static final String TOPIC = "my_topic";
    @Autowired
    private KafkaTemplate<String, String> kafkaTemplate;
    public void sendMessage(String key, String message) {
        kafkaTemplate.send(TOPIC, key, message);
        System.out.println("Message sent - Key: " + key + ", Value: " + message);
    }
}
4Ô∏è‚É£ Use the Producer in a Controller (optional):
@RestController
public class KafkaController {
    @Autowired
    private ProducerService producerService;
    @GetMapping("/send")
    public String sendMessage(@RequestParam String key, @RequestParam String message) {
        producerService.sendMessage(key, message);
        return "Message sent to Kafka with key: " + key;
    }
}
‚úÖ Now you can hit: http://localhost:8080/send?key=user123&message=HelloKafka


Q2. How do you create a Kafka Consumer in Spring Boot?
Use @KafkaListener(topics="topicName") and ConsumerFactory for configuration.
üß© By Following Steps:
1Ô∏è‚É£ Add dependency in pom.xml:
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
</dependency>
2Ô∏è‚É£ Configure Consumer in a @Configuration class:
@EnableKafka
@Configuration
public class KafkaConsumerConfig {
    @Bean
    public ConsumerFactory<String, String> consumerFactory() {
        Map<String, Object> props = new HashMap<>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");  // Kafka broker address
        props.put(ConsumerConfig.GROUP_ID_CONFIG, "my_group_id");              // Consumer group ID
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); 
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        return new DefaultKafkaConsumerFactory<>(props);
    }
    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, String> factory = 
                new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory());
        return factory;
    }
}
üìù Explanation of stored map data:
        - ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG
                    üëç Specifies Kafka broker address from where the consumer will read messages.
        - ConsumerConfig.GROUP_ID_CONFIG
                    üëç Defines the consumer group ‚Äî all consumers with the same ID share the work.
        - ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG
                    üëç Converts the message key from byte stream ‚Üí Java type.
        - ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG
                    üëç Converts the message value from byte stream ‚Üí Java type.
3Ô∏è‚É£ Create a Consumer Service using @KafkaListener:
@Service
public class ConsumerService {
    @KafkaListener(topics = "my_topic", groupId = "my_group_id")
    public void consumeMessage(String message) {
        System.out.println("Received message: " + message);
    }
}
4Ô∏è‚É£ Start your Spring Boot application :
When you run your application and a message is produced to the topic my_topic, the @KafkaListener method automatically receives and prints it.
5Ô∏è‚É£ Output Example :
Received message: HelloKafka


Q3. What is a Kafka key / message key , and why is it used?
-> used for partitioning : kafka uses the message key to decide which partition the message should go to.
-> ensure ordering :  message with the same key always go to the same partition.
-> optional : producer can send message with or without a key (if no key, kafka distributes messages in round-robin).
-> stored with message : the key is stored along with the message in kafka but doesn't effect the message content.
-> can be any data type: typically a string, but can be any serializable data.
Diagram :                         +----------------------------+
                                  |           TopicA           |
                                  |                            |
                      |-- KeyA -->|  +----------------------+  |
                      |           |  |    Partition 0       |  |
+-------------+       |           |  +----------------------+  |
|   Producer  | ------‚Üí           |                            |
+-------------+       |           |  +----------------------+  |
                      |-- KeyB -->|  |    Partition 1       |  |
                                  |  +----------------------+  |
                                  +----------------------------+

Q4. What is Kafka Producer Acknowledgment (acks) and  the difference between acks=0,1,all in Kafka Producer?
üëâ A setting to control durability:
- acks= 0   ‚Üí fire and forget.
- acks= 1   ‚Üí leader must ack.
- acks= all ‚Üí leader + replicas must ack (safest).

Q5. What is an Offset in Kafka?
üëâ A unique number (like an index) for each message in a partition. Consumers use it to track where they left off.
Diagram :     Topic: orders
              Partition: 0
+---------+---------+---------+---------+---------+---------+
| Offset: |    0    |    1    |    2    |    3    |    4    |
+---------+---------+---------+---------+---------+---------+
| Message | "A"     | "B"     | "C"     | "D"     | "E"     |
+---------+---------+---------+---------+---------+---------+
                                        ‚Üë
                                  Consumer is here
                              (Current offset = 3)
Note:- Who assigns it? : The Kafka broker automatically assigns the offset (not you, not the producer), when a message is successfully written to a partition.

Q6. What is the between assigning and committing offsets in Kafka?
‚öôÔ∏è There are two different concepts here:
| Action             | Who Does It            | Purpose                                                                                                          |
| -------------------| -----------------------| ---------------------------------------------------------------------------------------------------------------- |
| **Assign Offset**  | ‚úÖ **Kafka Broker**   | Happens **automatically** when a message is written to a partition. It gives each record a unique offset number. |
| **Commit Offset**  | ‚úÖ **Kafka Consumer** | Happens when a consumer **confirms** that it has successfully processed a message (so it won‚Äôt be re-read).      |

Q7. How do you commit offsets in Kafka?
Offsets are committed to keep track of which messages a consumer has already read.
It can be done in two ways:
       1Ô∏è‚É£ Automatically ‚Äì Kafka commits offsets on its own when enable.auto.commit=true.
                üëâ This means after reading messages, Kafka automatically saves your progress so you don‚Äôt read the same message again.
       2Ô∏è‚É£ Manually ‚Äì You can commit offsets yourself using Acknowledgment.acknowledge().
                üëâ This gives you full control ‚Äî you decide when a message is considered successfully processed before saving the offset.
Steps for üîß Manual Offset Commit in Spring Boot :
 Step 1: When you set : spring.kafka.consumer.enable-auto-commit=false
                üëâ you‚Äôre telling Kafka: ‚ÄúDon‚Äôt automatically mark messages as read. I‚Äôll do it myself after processing.‚Äù
Step 2: Update application.properties :
                    spring.kafka.consumer.enable-auto-commit=false
                    spring.kafka.listener.ack-mode=manual_immediate
                                - Explanation:
                                           - enable-auto-commit=false ‚Üí disables auto commit.
                                           - ack-mode=manual_immediate ‚Üí tells Spring Kafka you‚Äôll acknowledge manually, and commit immediately.
Step 3: Update your Kafka Listener :
Use the Acknowledgment object provided by Spring Kafka:
@Service
public class ConsumerService {
    @KafkaListener(topics = "my_topic", groupId = "my_group")
    public void consumeMessage(String message, Acknowledgment acknowledgment) {
        try {
            System.out.println("Received Message: " + message);
            // ‚úÖ Process your message here
            // (e.g., save to DB, send email, etc.)

            // ‚úÖ Manually commit the offset only after successful processing
            acknowledgment.acknowledge();
        } catch (Exception e) {
            System.err.println("Error while processing message: " + e.getMessage());
            // ‚ùå No acknowledgment here ‚Üí offset not committed ‚Üí message will be retried
        }
    }


Q8. What is the difference between Kafka‚Äôs at-most-once, at-least-once, and exactly-once delivery?
These terms describe how Kafka ensures that consumers see messages, especially when failures occur.It‚Äôs part of Kafka consumer-producer reliability configuration, not the basic sending logic.
these are Delivery Semantics :
| Delivery Type     | Meaning                                                                                                                   | Message Behavior                                              |
| ----------------- | ------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------- |
| **At-most-once**  | Messages are sent **once at most**, but may **never reach the consumer** if a failure occurs.                             | ‚ùå Some messages **may be lost** (never delivered).          |
| **At-least-once** | Messages are **guaranteed to be delivered**, but if failure happens before commit, Kafka may **resend** the same message. | ‚ö†Ô∏è Messages **may be duplicated** (delivered more than once).|
| **Exactly-once**  | Messages are delivered **once and only once**, using Kafka **transactions**.                                              | ‚úÖ No message lost, no duplication.                          |








(4) Kafka & Spring Boot Integration :
--------------------------------------

Q1. How to configure Kafka in Spring Boot?
Steps to Configure Kafka in Spring Boot :
 - Add Dependencies
        üëâ Include spring-kafka in your pom.xml (Maven) or build.gradle (Gradle).
 - Configure Application Properties
        üëâ Set Kafka broker address, consumer group ID, and other producer/consumer properties in application.properties or application.yml.
 - Create Producer Configuration
        üëâ Define a @Configuration class with a ProducerFactory and KafkaTemplate bean.
 - Create Consumer Configuration
        üëâ Define a @Configuration class with a ConsumerFactory and ConcurrentKafkaListenerContainerFactory bean.
 - Create Producer Service
        üëâ Autowire KafkaTemplate and use it to send messages to a topic.
 - Create Consumer Service
        üëâ Use @KafkaListener on a method to receive messages from a topic.
 - Run & Test
        üëâ Start your Spring Boot application and test sending/receiving messages.

Q2. How do you create multiple consumers for the same topic?
Steps to Create Multiple Consumers for the Same Topic
 - Create the Kafka Topic
       - Make sure the topic has multiple partitions.
            üëâ ‚ö†Ô∏è Each partition can be consumed by only one consumer in a consumer group at a time.
 - Define Consumer Group
            üëâ Assign the same group.id in application.properties or application.yml for all consumers.
            üëâ Consumers with the same group ID share partitions.
 - Create Multiple Consumer Services
            üëâ Implement multiple @KafkaListener methods or multiple classes.
             üëâ All should listen to the same topic.
 - Set Up Consumer Factory (Optional)
            üëâ Configure ConsumerFactory and ConcurrentKafkaListenerContainerFactory if custom settings are needed.
 - Start Application
            üëâ Spring Boot automatically assigns partitions to consumers in the same group.
            üëâ Messages are load balanced across the consumers.
 - Test
            üëâ Produce messages to the topic and observe that multiple consumers process messages in parallel, each handling different partitions.


Q3. How to send messages asynchronously in Spring Boot Kafka?
here asynchronously meaning :
In Kafka, sending messages asynchronously means that your program doesn‚Äôt wait for Kafka to confirm that the message was received. Instead, Your program sends the message and moves on, handling success or failure later via a callback.
Steps to Send Messages Asynchronously :
      - Use KafkaTemplate.send()
             - The send() method always returns a ListenableFuture, which allows async processing.
      - Attach a Callback
             - Use .addCallback() on the ListenableFuture to handle success or failure of message delivery.
Example :
@Autowired
private KafkaTemplate<String, String> kafkaTemplate;
private static final String TOPIC = "my_topic";
public void sendMessageAsync(String key, String message) {
    kafkaTemplate.send(TOPIC, key, message).addCallback(
        success -> System.out.println("Message sent successfully: " + message),
        failure -> System.err.println("Failed to send message: " + failure.getMessage())
    );
}
How it Works :
         - send() ‚Üí sends the message asynchronously.
         - .addCallback() ‚Üí lets you react when Kafka successfully stores the message or fails.
         - The calling thread doesn‚Äôt block, so your app continues executing.












































Q15. What is Kafka Replication?
---------------------------------
üëâ Each partition can be replicated across brokers for fault tolerance. One replica is leader, others are followers.


Q18. What is Kafka Serialization?
-----------------------------------
üëâ Serialization in Kafka means converting objects/data into a byte array before sending it to Kafka (Producer ‚Üí Broker).
- Kafka works with bytes only.
- So if you send a String, Integer, or even a Java object, it must first be serialized into bytes.
- Example:
   a. A StringSerializer converts "Hello" ‚Üí [72, 101, 108, 108, 111] (bytes).
   b. An IntegerSerializer converts 100 ‚Üí [0,0,0,100].

Q19. What is Kafka Deserialization?
---------------------------------------
üëâ Deserialization in Kafka means converting byte array back into an object when a Consumer reads data from Kafka.
Example:
     a. If Consumer uses StringDeserializer, it converts [72, 101, 108, 108, 111] ‚Üí "Hello".
     b. If Consumer uses IntegerDeserializer, it converts [0,0,0,100] ‚Üí 100.


Q20. Real-time use cases of Kafka?
-----------------------------------
üëâ Logging, monitoring, payment processing, fraud detection, real-time analytics, event-driven microservices.

Q21. What happens if a consumer goes down?
-------------------------------------------
üëâ Another consumer in the group will take over its partitions (rebalance).

Q22. What happens if a broker goes down?
------------------------------------------
üëâ Partition leader shifts to another replica (if replication is enabled).

Q23. What is Kafka Retention Policy?
--------------------------------------
üëâ How long Kafka keeps messages (based on time or size). Even if consumed, messages are retained.

Q24. What is Kafka Connect?
----------------------------
üëâ A tool for integrating Kafka with external systems (databases, Elasticsearch, etc.).


Q25. How do you monitor Kafka?
--------------------------------
üëâ Using Prometheus, Grafana, Confluent Control Center, Kafka Manager, or Spring Boot Actuator + Micrometer.




Q27. What is Kafka UI ?
---------------------------
web-based open source tool that provides an easy way to use interface for monitoring,managing and interacting with apache clusters,
including topics, partitions,consumer groups and messages.





(10) Steps to setup kafka in windows:

Step-1 : Download Zookeeper:

   URL : https://dlcdn.apache.org/zookeeper/zookeeper-3.9.2/apache-zookeeper-3.9.2-bin.tar.gz
   URL : https://dlcdn.apache.org/zookeeper/zookeeper-3.8.4/apache-zookeeper-3.8.4-bin.tar.gz

Step-2 : Download Apache Kafka:

	URL : https://downloads.apache.org/kafka/3.8.0/kafka_2.12-3.8.0.tgz

Step-3 : Set Path of ZOOKEEPER in Environment variables upto bin folder.

Step 4: Copy "zookeeper.properties" and "server.properties" files from "kafka/config" folder to "kafka/bin/windows" folder.

Step-5 : Start Zookeeper server from "kafka/bin/windows" root folder

    Command : zookeeper-server-start.bat zookeeper.properties

Step-6: Start Kafka Server using below command from "kafka/bin/windows" folder

    Command : kafka-server-start.bat server.properties

Note: If kafka server is stopped, delete kafka logs from temp folder and try again to start kafka server

Step-7 : Create Kakfa Topic from "kafka/bin/windows" root folder

Command : kafka-topics.bat --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic order_topic_1

Step-8 : View created Topics using below command

   Command : kafka-topics.bat --list --bootstrap-server localhost:9092


Kafka Bootstrap Server URL : http://localhost:9092/ or http://192.30.43.2:9092/ for linux server created in cloud








