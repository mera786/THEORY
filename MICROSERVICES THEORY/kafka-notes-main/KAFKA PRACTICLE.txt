
                                                           KAFKA
########################################################################################################################################


  Steps to setup kafka in windows
-----------------------------------------------------
(1) Download Zookeeper : https://dlcdn.apache.org/zookeeper/zookeeper-3.9.2/apache-zookeeper-3.9.2-bin.tar.gz
                    -> extract -> Set Path of ZOOKEEPER in Environment variables upto bin folder. (in my pc done).
(2) Download Apache Kafka : https://downloads.apache.org/kafka/3.8.0/kafka_2.12-3.8.0.tgz
                    -> only extract not set path of it.
(3) Copy "zookeeper.properties" and "server.properties" files from "kafka/config" folder to "kafka/bin/windows" folder. ( in my pc done).
(4) Start Zookeeper server from "kafka/bin/windows" root folder using cmd and run this commands , zookeeper-server-start.bat zookeeper.properties
(5) minimize cmd and open one more cmd by following Start Kafka Server using below command from "kafka/bin/windows" folder and run command kafka-server-start.bat server.properties
(6) open one more cmd, Create Kakfa Topic from "kafka/bin/windows" root folder and run command  kafka-topics.bat --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic order_topic_1
(8) View created Topics using below command , kafka-topics.bat --list --bootstrap-server localhost:9092

_______________________________________________________ EXAMPLES ________________________________________________________________________

To check if Zookeeper is running or not

Windows (CMD):
netstat -aon | findstr 2181

Linux / macOS:
lsof -i :2181


To check if kafka-server is running or not 

Windows (CMD):
netstat -aon | findstr 9092

Linux / macOS:
lsof -i :9092



Example-1 :                      CREATING A TOPIC 
*********** 

(1). Create test-topic : kafka-topics.bat --create --topic test-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1
(2) To List All Topics: kafka-topics.bat --list --bootstrap-server localhost:9092
(3)  How to Delete a Kafka Topic on Windows:  kafka-topics.bat --delete --topic <topic-name> --bootstrap-server localhost:9092

Note :- To test producer and consumer by default configuration of kafka using kafka  files.

producer run command: 
kafka-console-producer.bat --topic test-topic --bootstrap-server localhost:9092 -> hit enter
then write this message :
Hello Kafka
This is my first message

consumer run command :
kafka-console-consumer.bat --topic test-topic --from-beginning --bootstrap-server localhost:9092
now You’ll immediately see the messages:
Hello Kafka
This is my first message



Example-2 :                      CREATING A TOPIC WITH 2 partitions and 2 consumer ( same group of consumers)
*********** 
Note: in this from producer whatever we will send msge along with key 


(1) Create Topic With 2 partitions : 
kafka-topics.bat --create --topic orders --bootstrap-server localhost:9092 --partitions 2 --replication-factor 1

(2) To verify created or not : 
kafka-topics.bat --bootstrap-server localhost:9092 --topic orders --describe

(3) Start producer and send msge using key :
kafka-console-producer.bat --topic orders --bootstrap-server localhost:9092 --property parse.key=true --property key.separator=:

(4) Create Two Consumers for the 'orders' Topic Using the Same Group :
 POV: for better visibility open two screen exept for producer and run below command in both
     a. (1st screen) : kafka-console-consumer.bat --topic orders --from-beginning --bootstrap-server localhost:9092 --group og
     b. (2nd screen) : kafka-console-consumer.bat --topic orders --from-beginning --bootstrap-server localhost:9092 --group og

(5) To Check All Groups :
kafka-consumer-groups.bat --bootstrap-server localhost:9092 --list

(6) Info about specific consumer group :
kafka-consumer-groups.bat --bootstrap-server localhost:9092 --describe --group og




Example-3 :                      1 PRODUCER MULTIPLE CONSUMER GROUPS
*********** 
Note: - in one group you can create multiple consumer group.

(1) run producer :
kafka-console-producer.bat --topic orders --bootstrap-server localhost:9092 --property parse.key=true --property key.separator=:

(2) run consumer by creating group og1:
kafka-console-consumer.bat --topic orders --from-beginning --bootstrap-server localhost:9092 --group og1

(3) run consumer by creating group og2 :
kafka-console-consumer.bat --topic orders --from-beginning --bootstrap-server localhost:9092 --group og2

Note: now produce some message and see consumers.




                                         USING KAFKA UI

PRACTICLE :
************  

-> 1️⃣ Go to Kafka server.properties file:
cd <kafka-folder>/config/server.properties
now on windows press win+r 
paste: D:\KAFKA\kafka_2.12-3.8.0\config\server.properties
opened server.properties file now set.

-> 2️⃣ Set or update this property:
advertised.listeners=PLAINTEXT://<your-ip-address>:9092
Note:- 
a. find ip in windows:
ipconfig (so you will find instead of localhost some ip like,192.168.86.248
Replace <your-ip-address> with:
advertised.listeners=PLAINTEXT://192.168.1.10:9092
now saved and exit.

-> now run kafka-ui in docker:
-> install docker
-> run this command:
sudo docker run --rm -d -p 8080:8080 -e KAFKA_CLUSTERS_O_NAME=my-cluster -e KAFKA_CLUSTERS_O_BOOTSTRAPSERVERS=192.168.86.248:9092 --name kafkaui provectuslabs/kafka-ui




                                                         PRACTICAL WITH JAVA CODE
----------------------------------------------------------------------------------------------------------------------------------------------------------------
Note:- if wanted to create topic and this property (auto.create.topics.enable=false) then make it true in server.properties for automatically given topic
       create or manually create topic.


PRACTICAL -1     Creating publisher
-----------------------------------------------------
(1) create one spring boot project named cutomerApp having dependencies like, web, spring for apache kafka, spring for apache kafka stream
(2) to kafka interact with application:

  
   a. create Order Entity which will store API Request :

    public class Order {
    private String id;
    private String name;
    private Double price;
    private String email;
    }
      Note: provide getters and setters and also toString 


  b. Create Rest Controller Class:

    package com.app.controller;
    import com.app.entities.Order;
    import com.app.service.OrderService;
    import org.springframework.beans.factory.annotation.Autowired;
    import org.springframework.web.bind.annotation.PostMapping;
    import org.springframework.web.bind.annotation.RequestBody;
    import org.springframework.web.bind.annotation.RequestMapping;
    import org.springframework.web.bind.annotation.RestController;
    @RestController
    @RequestMapping("/api/v1/order")
    public class OrderRestController {

    @Autowired
    private OrderService service;

    @PostMapping("/create")
    public String createOrder(@RequestBody Order order) {
        String response = service.addMsg(order);
        return response;
    }
  }


     c. Create Service Class :

       package com.app.service;
       import com.app.AppConstant;
       import com.app.entities.Order;
       import org.springframework.beans.factory.annotation.Autowired;
       import org.springframework.kafka.core.KafkaTemplate;
       import org.springframework.stereotype.Service;
       @Service
       public class OrderService {

       @Autowired
       private KafkaTemplate<String, Order> kafkaTemplate;

       public String addMsg(Order order) {
        // sends msg to kafka topic
        kafkaTemplate.send(AppConstant.TOPIC,order.getId(), order); // id for sequence
        return "Msg Published To Kafka Topic";
      }
    }



     d. to keep topic and kafka host create AppConstant class

        public class AppConstant {
        public static final String TOPIC="order_topic";
        public static final String KAFKA_HOST="localhost:9092";
     }



   e. to connect kafka with cutomerApp create configuration class like, KafkaConfig.

     package com.app.config;
     import java.util.HashMap;
     import java.util.Map;
     import com.app.AppConstant;
     import com.app.entities.Order;
     import org.apache.kafka.clients.producer.ProducerConfig;
     import org.apache.kafka.common.serialization.StringSerializer;
     import org.springframework.context.annotation.Bean;
     import org.springframework.context.annotation.Configuration;
     import org.springframework.kafka.core.DefaultKafkaProducerFactory;
     import org.springframework.kafka.core.KafkaTemplate;
     import org.springframework.kafka.core.ProducerFactory;
     import org.springframework.kafka.support.serializer.JsonSerializer;
     @Configuration
     public class KafkaConfig {

      @Bean
      public ProducerFactory<String, Order> producerFactory() {

        Map<String, Object> kafkaProps = new HashMap<>();

        kafkaProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, AppConstant.KAFKA_HOST);
        kafkaProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        kafkaProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
        return new DefaultKafkaProducerFactory<>(kafkaProps);
      }

       @Bean
       public KafkaTemplate<String, Order> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
      }
    }



 


PRACTICAL -2     Creating consumerApp
-----------------------------------------------------

(1) create one spring boot project named hotelApp having dependencies like, web, spring for apache kafka, spring for apache kafka stream 


   a. create consumer service :
   ******************************
   package com.app.service;
   import com.app.constants.AppConstant;
   import com.app.payload.Order;
   import org.springframework.kafka.annotation.KafkaListener;
   import org.springframework.stereotype.Service;
   @Service
   public class KafkaConsumerService {

    private Order latestMessage; // Store latest Order object

    @KafkaListener(
            topics = AppConstant.TOPIC,
            groupId = "group_customer_order",
            containerFactory = "kafkaListenerFactory"
    )
    public void consumeMessage(Order order) {
        System.out.println("_____________ Msg fetched from Kafka _________________");
        System.out.println("ID: " + order.getId());
        System.out.println("Name: " + order.getName());
        System.out.println("Price: " + order.getPrice());
        System.out.println("Email: " + order.getEmail());

        this.latestMessage = order;
    }

    public Order getLatestMessage() {
     return latestMessage;
    }
 }


  b. create consumer controller :
 **********************************
  package com.app.controller;
  import com.app.payload.Order;
  import com.app.service.KafkaConsumerService;
  import org.springframework.web.bind.annotation.GetMapping;
  import org.springframework.web.bind.annotation.RequestMapping;
  import org.springframework.web.bind.annotation.RestController;
  @RestController
  @RequestMapping("/kafka")
  public class KafkaMessageController {

    private final KafkaConsumerService kafkaConsumerService;

    public KafkaMessageController(KafkaConsumerService kafkaConsumerService) {
        this.kafkaConsumerService = kafkaConsumerService;
    }

    @GetMapping("/latest-message")
    public Order getLatestKafkaMessage() {
        return kafkaConsumerService.getLatestMessage();
    }
   }



   c. copy entity and paste in hotel app and provide getters and setters :
  ***************************************************************************
    public class Order {
    private String id;
    private String name;
    private Double price;
    private String email;
   }


   d. Create constants class to define url & topic to consume data ( copy from publisher and paste):
   *************************************************************************************************
    package com.app;
    public class AppConstant {
    public static final String TOPIC="order_topic";
    public static final String KAFKA_HOST="localhost:9092";
    
   }


  e. Create Config clas to consume messages:
  *******************************************
   package com.app.config;
   import com.app.constants.AppConstant;
   import com.app.payload.Order;
   import org.apache.kafka.clients.consumer.ConsumerConfig;
   import org.apache.kafka.common.serialization.StringDeserializer;
   import org.springframework.context.annotation.Bean;
   import org.springframework.context.annotation.Configuration;
   import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
   import org.springframework.kafka.core.ConsumerFactory;
   import org.springframework.kafka.core.DefaultKafkaConsumerFactory;
   import org.springframework.kafka.support.serializer.JsonDeserializer;
   import java.util.HashMap;
   import java.util.Map;
   @Configuration
   public class KafkaConsumerConfig {

    @Bean
    public ConsumerFactory<String, Order> consumerFactory() {
        JsonDeserializer<Order> deserializer = new JsonDeserializer<>(Order.class);
        deserializer.addTrustedPackages("*"); // or your specific package name

        Map<String, Object> props = new HashMap<>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, AppConstant.KAFKA_HOST);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer.class);
        props.put(ConsumerConfig.GROUP_ID_CONFIG, "group_customer_order");
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");

        return new DefaultKafkaConsumerFactory<>(props, new StringDeserializer(), deserializer);
    }

      @Bean
      public ConcurrentKafkaListenerContainerFactory<String, Order> kafkaListenerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, Order> factory = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory());
        return factory;
    }
}

