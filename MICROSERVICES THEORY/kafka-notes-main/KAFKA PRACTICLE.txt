
                                                           KAFKA
########################################################################################################################################


  Steps to setup kafka in windows
-----------------------------------------------------
(1) Download Zookeeper : https://dlcdn.apache.org/zookeeper/zookeeper-3.9.2/apache-zookeeper-3.9.2-bin.tar.gz
                    -> extract -> Set Path of ZOOKEEPER in Environment variables upto bin folder. (in my pc done).
(2) Download Apache Kafka : https://downloads.apache.org/kafka/3.8.0/kafka_2.12-3.8.0.tgz
                    -> only extract not set path of it.
(3) Copy "zookeeper.properties" and "server.properties" files from "kafka/config" folder to "kafka/bin/windows" folder. ( in my pc done).
(4) Start Zookeeper server from "kafka/bin/windows" root folder using cmd and run this commands , zookeeper-server-start.bat zookeeper.properties
(5) minimize cmd and open one more cmd by following Start Kafka Server using below command from "kafka/bin/windows" folder and run command kafka-server-start.bat server.properties
(6) open one more cmd, Create Kakfa Topic from "kafka/bin/windows" root folder and run command  kafka-topics.bat --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic order_topic_1
(8) View created Topics using below command , kafka-topics.bat --list --bootstrap-server localhost:9092

_______________________________________________________ EXAMPLES ________________________________________________________________________

Example-1 :                      CREATING A TOPIC 
*********** 

(1). Create test-topic : kafka-topics.bat --create --topic test-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1
(2) To List All Topics: kafka-topics.bat --list --bootstrap-server localhost:9092
(3)  How to Delete a Kafka Topic on Windows:  kafka-topics.bat --delete --topic <topic-name> --bootstrap-server localhost:9092

Note :- To test producer and consumer by default configuration of kafka using kafka  files.

producer run command: 
kafka-console-producer.bat --topic test-topic --bootstrap-server localhost:9092 -> hit enter
then write this message :
Hello Kafka
This is my first message

consumer run command :
kafka-console-consumer.bat --topic test-topic --from-beginning --bootstrap-server localhost:9092
now Youâ€™ll immediately see the messages:
Hello Kafka
This is my first message



Example-2 :                      CREATING A TOPIC WITH 2 partitions and 2 consumer ( same group of consumers)
*********** 
Note: in this from producer whatever we will send msge along with key 


(1) Create Topic With 2 partitions : 
kafka-topics.bat --create --topic orders --bootstrap-server localhost:9092 --partitions 2 --replication-factor 1

(2) To verify created or not : 
kafka-topics.bat --bootstrap-server localhost:9092 --topic orders --describe

(3) Start producer and send msge using key :
kafka-console-producer.bat --topic orders --bootstrap-server localhost:9092 --property parse.key=true --property key.separator=:

(4) Create Two Consumers for the 'orders' Topic Using the Same Group :
 POV: for better visibility open two screen exept for producer and run below command in both
     a. (1st screen) : kafka-console-consumer.bat --topic orders --from-beginning --bootstrap-server localhost:9092 --group og
     b. (2nd screen) : kafka-console-consumer.bat --topic orders --from-beginning --bootstrap-server localhost:9092 --group og

(5) To Check All Groups :
kafka-consumer-groups.bat --bootstrap-server localhost:9092 --list

(6) Info about specific consumer group :
kafka-consumer-groups.bat --bootstrap-server localhost:9092 --describe --group og




Example-3 :                      1 PRODUCER MULTIPLE CONSUMER GROUPS
*********** 
Note: - in one group you can create multiple consumer group.

(1) run producer :
kafka-console-producer.bat --topic orders --bootstrap-server localhost:9092 --property parse.key=true --property key.separator=:

(2) run consumer by creating group og1:
kafka-console-consumer.bat --topic orders --from-beginning --bootstrap-server localhost:9092 --group og1

(3) run consumer by creating group og2 :
kafka-console-consumer.bat --topic orders --from-beginning --bootstrap-server localhost:9092 --group og2

Note: now produce some message and see consumers.























PRACTICAL -2     Creating publisher
-----------------------------------------------------
(1) create one spring boot project named cutomerApp having dependencies like, web, spring for apache kafka, spring for apache kafka stream
(2) to kafka interact with application:


     a. to keep topic and kafka host create AppConstant class



        public class AppConstant {
        public static final String TOPIC="order_topic";
        public static final String KAFKA_HOST="localhost:9092";
     }




  b. create Order Entity which will store API Request




     public class Order {
    private String id;
    private String name;
    private Double price;
    private String email;
    }
  Note: provide getters and setters and also toString 




   c. to connect kafka with cutomerApp create configuration class like, KafkaConfig




     package com.app.config;

import java.util.HashMap;
import java.util.Map;

import com.app.AppConstant;
import com.app.entities.Order;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.serialization.StringSerializer;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.core.DefaultKafkaProducerFactory;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.core.ProducerFactory;
import org.springframework.kafka.support.serializer.JsonSerializer;

@Configuration
public class KafkaConfig {

    @Bean
    public ProducerFactory<String, Order> producerFactory() {

        Map<String, Object> kafkaProps = new HashMap<>();

        kafkaProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, AppConstant.KAFKA_HOST);
        kafkaProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        kafkaProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);

        return new DefaultKafkaProducerFactory<>(kafkaProps);
    }

    @Bean
    public KafkaTemplate<String, Order> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }
}



  d. Create Service Class :


 
 package com.app.service;

import com.app.AppConstant;
import com.app.entities.Order;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Service;


@Service
public class OrderService {

    @Autowired
    private KafkaTemplate<String, Order> kafkaTemplate;

    public String addMsg(Order order) {

        // sends msg to kafka topic
        kafkaTemplate.send(AppConstant.TOPIC,order.getId(), order); // id for sequence

        return "Msg Published To Kafka Topic";
    }
}




  e. Create Rest Controller Class:



package com.app.controller;

import com.app.entities.Order;
import com.app.service.OrderService;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestBody;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
@RequestMapping("/api/v1/order")
public class OrderRestController {

    @Autowired
    private OrderService service;

    @PostMapping("/create")
    public String createOrder(@RequestBody Order order) {
        String response = service.addMsg(order);
        return response;
    }

}



PRACTICAL -2     Creating consumerApp
-----------------------------------------------------

(1) create one spring boot project named hotelApp having dependencies like, web, spring for apache kafka, spring for apache kafka stream 
(2) Create constants class to define url & topic to consume data ( copy from publisher and paste):
  
    package com.app;

public class AppConstant {
    public static final String TOPIC="order_topic";
    public static final String KAFKA_HOST="localhost:9092";
    
}


(3) copy entity and paste in hotel app and provide getters and setters :

   public class Order {
    private String id;
    private String name;
    private Double price;
    private String email;
}


(4)  Create Config clas to consume messages:

 
package com.app.config;

import java.util.HashMap;
import java.util.Map;

import com.app.AppConstant;
import com.app.entities.Order;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
import org.springframework.kafka.core.ConsumerFactory;
import org.springframework.kafka.core.DefaultKafkaConsumerFactory;
import org.springframework.kafka.support.serializer.JsonDeserializer;


@Configuration
public class KafkaConsumerConfig {

    @Bean
    public ConsumerFactory<String, Order> consumerFactory() {

        Map<String, Object> kafkaConfigProps = new HashMap<String, Object>();

        kafkaConfigProps .put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, AppConstant.KAFKA_HOST);
        kafkaConfigProps .put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        kafkaConfigProps .put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer.class);

        return new DefaultKafkaConsumerFactory<>(kafkaConfigProps, new StringDeserializer(), new JsonDeserializer<>());

    }

    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, Order> kafkaListnerFactory() {

        ConcurrentKafkaListenerContainerFactory<String, Order> factory =
                new ConcurrentKafkaListenerContainerFactory<>();

        factory.setConsumerFactory(consumerFactory());

        return factory;
    }

}



(5) create consumer service :


package com.app.service;

import com.app.AppConstant;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Service;

@Service
public class KafkaConsumerService {

    private String latestMessage; // Stores the latest Kafka message

    @KafkaListener(topics = AppConstant.TOPIC, groupId = "group_customer_order")
    public void consumeMessage(String order) {
        System.out.println("_____________ Msg fetched from Kafka _________________");
        System.out.println(order);
        this.latestMessage = order; // Store the message for retrieval
    }

    public String getLatestMessage() {
        return latestMessage; // Expose latest message for the controller
    }
}


(6) create consumer controller :

package com.app.controller;

import com.app.service.KafkaConsumerService;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
@RequestMapping("/kafka")
public class KafkaMessageController {

    private final KafkaConsumerService kafkaConsumerService;

    public KafkaMessageController(KafkaConsumerService kafkaConsumerService) {
        this.kafkaConsumerService = kafkaConsumerService;
    }

    @GetMapping("/latest-message")
    public String getLatestKafkaMessage() {
        return kafkaConsumerService.getLatestMessage();
    }
}



(7) now give the json body :

 {
    "id":"f-1",
    "name":"sam",
    "price":50.2,
    "email":"sam@gmail.com"
}
 
and hit the url : http://localhost:8081/api/v1/order/create
